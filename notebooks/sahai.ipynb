{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfAdmissions = pd.read_csv(\"../data/ADMISSIONS.csv\")\n",
    "\n",
    "dfDiagnoses = pd.read_csv(\"../data/DIAGNOSES_ICD.csv\")\n",
    "\n",
    "dfTitle = pd.read_csv(\"../data/d_icd_diagnoses.csv\")\n",
    "\n",
    "df = pd.merge(dfAdmissions, dfDiagnoses, how=\"inner\", on=['SUBJECT_ID'])\n",
    "\n",
    "#drop na values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creating vector of HAI related to pneumonia, and HAP\n",
    "\n",
    "hcapCode = [\"48230\",\"48231\",\"48232\",\"48233\", \"48234\", \"48235\", \"48236\", \"48237\", \"48238\", \n",
    "            \"48239\", \"48240\", \"4830\", \"4822\", \"4820\", \"48240\", \"48241\", \"48242\", \"48243\",\n",
    "           \"48244\", \"48245\", \"48246\", \"48247\", \"48248\", \"48249\", \"48282\", \"48281\", \"48283\",\n",
    "           \"48284\", \"48289\"]\n",
    "\n",
    "#creating boolean values that are HAI related to pneumonia, and HAP\n",
    "df['is_it_HAI'] = df['ICD9_CODE'].map(lambda x: any(x == i for i in hcapCode)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of HAIs cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['SUBJECT_ID'][df['is_it_HAI']].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053\n"
     ]
    }
   ],
   "source": [
    "#finding all unique subject_id\n",
    "subjectID_All = df['SUBJECT_ID'].unique()\n",
    "\n",
    "#finding the subject_id with the HAI\n",
    "subjectID_HAI = df['SUBJECT_ID'][df['is_it_HAI']].unique()\n",
    "\n",
    "#total number of cases remainding \n",
    "print(len(subjectID_All))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of HAI cases (123, 2)\n",
      "Total number of cases (2053, 25)\n",
      "Total number of HAI Cases 123.0\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "dfHAI = pd.DataFrame()\n",
    "dfHAI['SUBJECT_ID'] = subjectID_HAI\n",
    "dfHAI['is_it_HAI'] = 1\n",
    "print('Total number of HAI cases', dfHAI.shape)\n",
    "\n",
    "#drop duplicate\n",
    "df = df.drop_duplicates('SUBJECT_ID')\n",
    "\n",
    "#merge dataframes\n",
    "dfFinal = pd.merge(df, dfHAI, how=\"left\", on=['SUBJECT_ID'])\n",
    "dfFinal = dfFinal.replace('NaN', 0)\n",
    "print('Total number of cases', dfFinal.shape)\n",
    "print('Total number of HAI Cases', dfFinal['is_it_HAI_y'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selecting the relevant variables for logistic regression\n",
    "dfFinal = dfFinal[['INSURANCE','LANGUAGE','RELIGION','MARITAL_STATUS','ETHNICITY','is_it_HAI_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummy variables\n",
    "\n",
    "dummy_insurance = pd.get_dummies(dfFinal['INSURANCE'], prefix='INSURANCE')\n",
    "dummy_language = pd.get_dummies(dfFinal['LANGUAGE'], prefix = 'LANGUAGE')\n",
    "dummy_religion = pd.get_dummies(dfFinal['RELIGION'], prefix = 'RELIGION')\n",
    "dummy_maritalStatus = pd.get_dummies(dfFinal['MARITAL_STATUS'], prefix = 'MARITAL_STATUS')\n",
    "dummy_ethnicity = pd.get_dummies(dfFinal['ETHNICITY'], prefix = 'ETHNICITY')\n",
    "\n",
    "#create a new data frame to fit the dummy variables\n",
    "colsToKeep = ['is_it_HAI_y']\n",
    "data = dfFinal[colsToKeep].join(dummy_insurance.ix[:, 'INSURANCE_Medicaid':])\n",
    "data = data.join(dummy_language.ix[:, 'LANGUAGE_* FU':])\n",
    "data = data.join(dummy_religion.ix[:, 'RELIGION_BAPTIST':])\n",
    "data = data.join(dummy_maritalStatus.ix[:, 'MARITAL_STATUS_LIFE PARTNER':])\n",
    "data = data.join(dummy_ethnicity.ix[:, 'ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "train_cols = data.columns[1:]\n",
    "\n",
    "logitModel = logistic.fit(data[train_cols], data['is_it_HAI_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00527     0.17007421 -0.13722057 -0.6319552  -0.15180349 -0.04178479\n",
      "  -0.20659271 -0.06117407 -0.04688902 -0.10099955 -0.07161925 -0.05793265\n",
      "  -0.10099955 -0.12673119  0.86296729 -0.14897084  0.86738604  0.71294436\n",
      "  -0.08935306  0.17708546 -0.03637894 -0.37870897 -0.23843291 -0.59149185\n",
      "   0.26425863 -0.13167681 -0.38545577 -0.04508461 -0.16841202 -0.07013045\n",
      "  -0.08762275  1.19128529 -0.16648692 -0.08512805 -0.35026016 -1.07986765\n",
      "  -0.14987721 -0.55769807 -0.42599703 -0.7073037  -0.35706717 -0.34416275\n",
      "  -0.24857694  0.42987268 -0.07930218 -0.30094864 -0.37613544 -0.09092447\n",
      "   0.5444868  -0.19574878  0.22265011  0.244857    0.33959508 -0.33745692\n",
      "  -0.67272629 -0.0982113  -0.09244441 -0.18026697 -0.31710303 -0.65924671\n",
      "  -0.10766175  0.19876177 -0.09128789 -0.08935306  0.0545893  -0.10280664\n",
      "  -0.03985465 -0.05735032 -0.1887334  -0.16275921 -0.121808   -0.34485402\n",
      "  -0.37364753 -0.11867913 -0.0564717  -0.03890417 -0.35868147 -0.14951263\n",
      "  -0.34261459  0.22992886 -0.31511951  0.75808277  0.28062981  0.37668474\n",
      "   0.01279434 -0.13065486 -0.22975472 -0.50573776]]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "\n",
    "print(logitModel.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the values\n",
    "\n",
    "logitModel.predict(data[train_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split into training and testing data set\n",
    "\n",
    "split = np.random.rand(len(data)) < 0.5\n",
    "\n",
    "test = data[split]\n",
    "\n",
    "train = data[~split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data\n",
    "\n",
    "logitModel = logistic.fit(train[train_cols], train['is_it_HAI_y'])\n",
    "\n",
    "#predict the values\n",
    "\n",
    "logitModel.predict(train[train_cols]).sum()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
